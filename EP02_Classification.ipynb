{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cee1023a",
   "metadata": {},
   "source": [
    "# EP02_Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22000b25",
   "metadata": {},
   "source": [
    "## Project 01_load digits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad1b0b0",
   "metadata": {},
   "source": [
    "### 1. 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dcf43a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a38efe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "digits_data = digits.data\n",
    "digits_label = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df60ed0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(digits_data.shape)\n",
    "digits_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b65dc2e",
   "metadata": {},
   "source": [
    "- digits_data에 저장된 데이터와 형식 확인\n",
    "- 1797개의 digit 데이터 확인\n",
    "- 각각의 데이터에 64개의 값이 저장되어 있음을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1bee950b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797,)\n",
      "[0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9]\n",
      "[0 1 2 3 4 5 6 7 8 9]\n"
     ]
    }
   ],
   "source": [
    "print(digits_label.shape)\n",
    "print(digits_label[:20])\n",
    "print(digits.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69379df8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(digits.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771f37d0",
   "metadata": {},
   "source": [
    "### 2. 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "375e7dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of X_train: 1257 number of X_test: 540\n",
      "(1257, 64) (1257,)\n",
      "(540, 64) (540,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(digits_data,\n",
    "                                                   digits_label,\n",
    "                                                   test_size=0.30,\n",
    "                                                   random_state=5)\n",
    "\n",
    "print('number of X_train:', len(X_train), 'number of X_test:', len(X_test))\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732d5510",
   "metadata": {},
   "source": [
    "- train data & test data 로 split.\n",
    "- 30%의 test data size로 구성\n",
    "- 1,797개의 데이터 셋 중, train data (1257), test data (540)\n",
    "- random(5)으로 섞어서 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bae2e64",
   "metadata": {},
   "source": [
    "### 3. 다양한 모델로 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0332c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=32)\n",
    "random_forest = RandomForestClassifier(random_state=32)\n",
    "svm_model = svm.SVC()\n",
    "sgd_model = SGDClassifier()\n",
    "logistic_model = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82fe41da",
   "metadata": {},
   "source": [
    "- 아래 5개의 모델로 구현\n",
    " - Decision Tree (decision_tree)\n",
    " - Random Forest (random_forest)\n",
    " - SVM (svm_model)\n",
    " - SGD Classifier (sgd_model)\n",
    " - Logistic Regression (logistic_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af64196f",
   "metadata": {},
   "source": [
    "#### 3-1. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "179a041c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.96        58\n",
      "           1       0.73      0.88      0.80        52\n",
      "           2       0.89      0.84      0.87        58\n",
      "           3       0.89      0.81      0.85        59\n",
      "           4       0.75      0.77      0.76        43\n",
      "           5       0.88      0.88      0.88        64\n",
      "           6       0.95      0.89      0.92        47\n",
      "           7       0.96      0.78      0.86        59\n",
      "           8       0.76      0.78      0.77        50\n",
      "           9       0.77      0.94      0.85        50\n",
      "\n",
      "    accuracy                           0.85       540\n",
      "   macro avg       0.86      0.85      0.85       540\n",
      "weighted avg       0.86      0.85      0.85       540\n",
      "\n",
      "[[55  0  0  0  1  1  0  0  1  0]\n",
      " [ 0 46  2  0  0  0  0  0  1  3]\n",
      " [ 0  4 49  2  0  1  1  0  1  0]\n",
      " [ 0  1  3 48  1  0  0  0  3  3]\n",
      " [ 0  5  0  0 33  2  1  1  0  1]\n",
      " [ 1  0  0  0  0 56  0  0  2  5]\n",
      " [ 0  0  0  0  3  1 42  0  1  0]\n",
      " [ 0  2  0  2  6  0  0 46  3  0]\n",
      " [ 0  3  1  2  0  3  0  0 39  2]\n",
      " [ 0  2  0  0  0  0  0  1  0 47]]\n"
     ]
    }
   ],
   "source": [
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred_dicision_tree = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_dicision_tree))\n",
    "print(confusion_matrix(y_test, y_pred_dicision_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ce8318",
   "metadata": {},
   "source": [
    "- 결과 : 86%의 정확도이지만, precision과 recall의 편차가 큰게 확인 됨. -> 모델성능이 좋다고 볼 순 없음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bd2c8c",
   "metadata": {},
   "source": [
    "#### 3-2. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6b54a94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        58\n",
      "           1       0.96      1.00      0.98        52\n",
      "           2       0.98      1.00      0.99        58\n",
      "           3       1.00      0.92      0.96        59\n",
      "           4       0.98      0.98      0.98        43\n",
      "           5       0.97      0.97      0.97        64\n",
      "           6       1.00      0.98      0.99        47\n",
      "           7       0.98      0.98      0.98        59\n",
      "           8       0.96      0.96      0.96        50\n",
      "           9       0.91      0.98      0.94        50\n",
      "\n",
      "    accuracy                           0.97       540\n",
      "   macro avg       0.97      0.97      0.97       540\n",
      "weighted avg       0.97      0.97      0.97       540\n",
      "\n",
      "[[57  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 52  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 58  0  0  0  0  0  0  0]\n",
      " [ 0  1  0 54  0  1  0  0  1  2]\n",
      " [ 0  0  0  0 42  0  0  1  0  0]\n",
      " [ 0  0  0  0  0 62  0  0  0  2]\n",
      " [ 0  0  0  0  0  0 46  0  1  0]\n",
      " [ 0  0  0  0  0  0  0 58  0  1]\n",
      " [ 0  1  1  0  0  0  0  0 48  0]\n",
      " [ 0  0  0  0  0  1  0  0  0 49]]\n"
     ]
    }
   ],
   "source": [
    "random_forest.fit(X_train, y_train)\n",
    "y_pred_random_forest = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_random_forest))\n",
    "print(confusion_matrix(y_test, y_pred_random_forest))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9177da",
   "metadata": {},
   "source": [
    "- 결과 : 97%의 정확도. precision과 recall의 편차가 작음. -> 모델성능이 좋음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4452beee",
   "metadata": {},
   "source": [
    "#### 3-3. SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5e118d17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        58\n",
      "           1       0.98      1.00      0.99        52\n",
      "           2       1.00      1.00      1.00        58\n",
      "           3       1.00      0.97      0.98        59\n",
      "           4       1.00      1.00      1.00        43\n",
      "           5       0.97      0.98      0.98        64\n",
      "           6       1.00      1.00      1.00        47\n",
      "           7       1.00      0.98      0.99        59\n",
      "           8       0.96      0.96      0.96        50\n",
      "           9       0.94      0.96      0.95        50\n",
      "\n",
      "    accuracy                           0.99       540\n",
      "   macro avg       0.99      0.99      0.99       540\n",
      "weighted avg       0.99      0.99      0.99       540\n",
      "\n",
      "[[58  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 52  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 58  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 57  0  1  0  0  1  0]\n",
      " [ 0  0  0  0 43  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 63  0  0  0  1]\n",
      " [ 0  0  0  0  0  0 47  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 58  0  1]\n",
      " [ 0  1  0  0  0  0  0  0 48  1]\n",
      " [ 0  0  0  0  0  1  0  0  1 48]]\n"
     ]
    }
   ],
   "source": [
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm_model = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_svm_model))\n",
    "print(confusion_matrix(y_test, y_pred_svm_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94c5819",
   "metadata": {},
   "source": [
    "- 결과 : 99%를 넘어선 100%에 가까운 정확도. precision과 recall의 편차가 완벽에 가까움."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "289f6300",
   "metadata": {},
   "source": [
    "#### 3-4. SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b512f3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99        58\n",
      "           1       0.91      0.96      0.93        52\n",
      "           2       0.98      1.00      0.99        58\n",
      "           3       1.00      0.88      0.94        59\n",
      "           4       0.96      1.00      0.98        43\n",
      "           5       0.93      0.97      0.95        64\n",
      "           6       1.00      0.96      0.98        47\n",
      "           7       1.00      0.95      0.97        59\n",
      "           8       0.95      0.82      0.88        50\n",
      "           9       0.80      0.98      0.88        50\n",
      "\n",
      "    accuracy                           0.95       540\n",
      "   macro avg       0.95      0.95      0.95       540\n",
      "weighted avg       0.95      0.95      0.95       540\n",
      "\n",
      "[[57  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 50  1  0  0  1  0  0  0  0]\n",
      " [ 0  0 58  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 52  0  3  0  0  1  3]\n",
      " [ 0  0  0  0 43  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 62  0  0  0  2]\n",
      " [ 0  1  0  0  0  0 45  0  1  0]\n",
      " [ 0  0  0  0  1  0  0 56  0  2]\n",
      " [ 0  4  0  0  0  0  0  0 41  5]\n",
      " [ 0  0  0  0  0  1  0  0  0 49]]\n"
     ]
    }
   ],
   "source": [
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred_sgd_model = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_sgd_model))\n",
    "print(confusion_matrix(y_test, y_pred_sgd_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1ac294",
   "metadata": {},
   "source": [
    "- 결과 : 95%의 정확도. precision과 recall의 편차가 어느정도 있음."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52529e8",
   "metadata": {},
   "source": [
    "#### 3-5. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "efad50e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        58\n",
      "           1       0.94      0.94      0.94        52\n",
      "           2       0.95      1.00      0.97        58\n",
      "           3       0.98      0.93      0.96        59\n",
      "           4       0.95      0.93      0.94        43\n",
      "           5       0.97      0.95      0.96        64\n",
      "           6       1.00      0.98      0.99        47\n",
      "           7       0.98      0.97      0.97        59\n",
      "           8       0.94      0.94      0.94        50\n",
      "           9       0.91      0.98      0.94        50\n",
      "\n",
      "    accuracy                           0.96       540\n",
      "   macro avg       0.96      0.96      0.96       540\n",
      "weighted avg       0.96      0.96      0.96       540\n",
      "\n",
      "[[58  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 49  1  1  0  0  0  0  1  0]\n",
      " [ 0  0 58  0  0  0  0  0  0  0]\n",
      " [ 0  0  1 55  0  1  0  0  1  1]\n",
      " [ 0  2  0  0 40  0  0  1  0  0]\n",
      " [ 0  0  0  0  1 61  0  0  0  2]\n",
      " [ 0  0  0  0  0  0 46  0  1  0]\n",
      " [ 0  0  0  0  1  0  0 57  0  1]\n",
      " [ 0  1  1  0  0  0  0  0 47  1]\n",
      " [ 0  0  0  0  0  1  0  0  0 49]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_logistic_model = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_logistic_model))\n",
    "print(confusion_matrix(y_test, y_pred_logistic_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f39c3a",
   "metadata": {},
   "source": [
    "- 결과 : 96%의 정확도. \n",
    "- Warning : lbfgs 가 수렴에 실패함. 이유? -> 분석 필요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffb3870",
   "metadata": {},
   "source": [
    "## Project 02_Load Wine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bfd868",
   "metadata": {},
   "source": [
    "### Project 01 과 같이,\n",
    "### 1. 데이터 준비 -> 2. 데이터 분리 -> 3. 다양한 방법으로의 학습 -> 결론 순으로 이어짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4bc5a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 13)\n",
      "(178,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
      "['class_0' 'class_1' 'class_2']\n",
      "number of X_train: 124 number of X_test: 54\n",
      "(124, 13) (124,)\n",
      "(54, 13) (54,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "wine = load_wine()\n",
    "wine_data = wine.data\n",
    "wine_label = wine.target\n",
    "\n",
    "print(wine_data.shape)\n",
    "wine_data[0]\n",
    "\n",
    "wine.feature_names\n",
    "\n",
    "print(wine_label.shape)\n",
    "print(wine_label[:])\n",
    "print(wine.target_names)\n",
    "\n",
    "#print(wine.DESCR) #코드 가독 편의상 생략\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine_data,\n",
    "                                                   wine_label,\n",
    "                                                   test_size=0.30,\n",
    "                                                   random_state=5)\n",
    "\n",
    "print('number of X_train:', len(X_train), 'number of X_test:', len(X_test))\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35b12b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93        23\n",
      "           1       0.89      0.89      0.89        18\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.93        54\n",
      "   macro avg       0.92      0.93      0.93        54\n",
      "weighted avg       0.93      0.93      0.93        54\n",
      "\n",
      "[[21  2  0]\n",
      " [ 1 16  1]\n",
      " [ 0  0 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        23\n",
      "           1       1.00      0.94      0.97        18\n",
      "           2       0.93      1.00      0.96        13\n",
      "\n",
      "    accuracy                           0.98        54\n",
      "   macro avg       0.98      0.98      0.98        54\n",
      "weighted avg       0.98      0.98      0.98        54\n",
      "\n",
      "[[23  0  0]\n",
      " [ 0 17  1]\n",
      " [ 0  0 13]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.74      0.81        23\n",
      "           1       0.60      0.83      0.70        18\n",
      "           2       0.40      0.31      0.35        13\n",
      "\n",
      "    accuracy                           0.67        54\n",
      "   macro avg       0.63      0.63      0.62        54\n",
      "weighted avg       0.68      0.67      0.66        54\n",
      "\n",
      "[[17  1  5]\n",
      " [ 2 15  1]\n",
      " [ 0  9  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.83      0.78        23\n",
      "           1       0.50      0.78      0.61        18\n",
      "           2       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.61        54\n",
      "   macro avg       0.41      0.53      0.46        54\n",
      "weighted avg       0.48      0.61      0.53        54\n",
      "\n",
      "[[19  4  0]\n",
      " [ 4 14  0]\n",
      " [ 3 10  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.96      0.92        23\n",
      "           1       0.82      0.78      0.80        18\n",
      "           2       0.92      0.85      0.88        13\n",
      "\n",
      "    accuracy                           0.87        54\n",
      "   macro avg       0.87      0.86      0.87        54\n",
      "weighted avg       0.87      0.87      0.87        54\n",
      "\n",
      "[[22  1  0]\n",
      " [ 3 14  1]\n",
      " [ 0  2 11]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#3-1. decision_tree\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred_dicision_tree = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_dicision_tree))\n",
    "print(confusion_matrix(y_test, y_pred_dicision_tree))\n",
    "\n",
    "#3-2. Random Forest\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred_random_forest = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_random_forest))\n",
    "print(confusion_matrix(y_test, y_pred_random_forest))\n",
    "\n",
    "#3-3. SVM\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm_model = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_svm_model))\n",
    "print(confusion_matrix(y_test, y_pred_svm_model))\n",
    "\n",
    "#3-4. SGD\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred_sgd_model = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_sgd_model))\n",
    "print(confusion_matrix(y_test, y_pred_sgd_model))\n",
    "\n",
    "#3-5. Logistic Regression\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_logistic_model = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_logistic_model))\n",
    "print(confusion_matrix(y_test, y_pred_logistic_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20efd51",
   "metadata": {},
   "source": [
    "- 결과_1 : 93%의 정확도. \n",
    "- 결과_2 : 98%의 정확도. \n",
    "- 결과_3 : 67%의 정확도. \n",
    "- 결과_4 : 61%의 정확도. \n",
    "- 결과_5 : 87%의 정확도. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55ead95",
   "metadata": {},
   "source": [
    "## Project 03_Load Breast Cancer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ca9c9b",
   "metadata": {},
   "source": [
    "### Project 01 과 같이,\n",
    "### 1. 데이터 준비 -> 2. 데이터 분리 -> 3. 다양한 방법으로의 학습 -> 결론 순으로 이어짐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6726d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "(569,)\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      "['malignant' 'benign']\n",
      "number of X_train: 398 number of X_test: 171\n",
      "(398, 30) (398,)\n",
      "(171, 30) (171,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer = load_breast_cancer()\n",
    "cancer_data = cancer.data\n",
    "cancer_label = cancer.target\n",
    "\n",
    "print(cancer_data.shape)\n",
    "cancer_data[0]\n",
    "\n",
    "cancer.feature_names\n",
    "\n",
    "print(cancer_label.shape)\n",
    "print(cancer_label[:])\n",
    "print(cancer.target_names)\n",
    "\n",
    "#print(cancer.DESCR) #코드 가독 편의상 생략\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer_data,\n",
    "                                                   cancer_label,\n",
    "                                                   test_size=0.30,\n",
    "                                                   random_state=5)\n",
    "\n",
    "print('number of X_train:', len(X_train), 'number of X_test:', len(X_test))\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a0d8f9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90        61\n",
      "           1       0.95      0.94      0.94       110\n",
      "\n",
      "    accuracy                           0.93       171\n",
      "   macro avg       0.92      0.93      0.92       171\n",
      "weighted avg       0.93      0.93      0.93       171\n",
      "\n",
      "[[ 56   5]\n",
      " [  7 103]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97        61\n",
      "           1       0.97      0.99      0.98       110\n",
      "\n",
      "    accuracy                           0.98       171\n",
      "   macro avg       0.98      0.97      0.97       171\n",
      "weighted avg       0.98      0.98      0.98       171\n",
      "\n",
      "[[ 58   3]\n",
      " [  1 109]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        61\n",
      "           1       0.95      1.00      0.97       110\n",
      "\n",
      "    accuracy                           0.96       171\n",
      "   macro avg       0.97      0.95      0.96       171\n",
      "weighted avg       0.97      0.96      0.96       171\n",
      "\n",
      "[[ 55   6]\n",
      " [  0 110]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.93      0.88        61\n",
      "           1       0.96      0.90      0.93       110\n",
      "\n",
      "    accuracy                           0.91       171\n",
      "   macro avg       0.90      0.92      0.91       171\n",
      "weighted avg       0.92      0.91      0.91       171\n",
      "\n",
      "[[57  4]\n",
      " [11 99]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93        61\n",
      "           1       0.96      0.97      0.96       110\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.95      0.95      0.95       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n",
      "[[ 56   5]\n",
      " [  3 107]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "#3-1. decision_tree\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred_dicision_tree = decision_tree.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_dicision_tree))\n",
    "print(confusion_matrix(y_test, y_pred_dicision_tree))\n",
    "\n",
    "#3-2. Random Forest\n",
    "random_forest.fit(X_train, y_train)\n",
    "y_pred_random_forest = random_forest.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_random_forest))\n",
    "print(confusion_matrix(y_test, y_pred_random_forest))\n",
    "\n",
    "#3-3. SVM\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm_model = svm_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_svm_model))\n",
    "print(confusion_matrix(y_test, y_pred_svm_model))\n",
    "\n",
    "#3-4. SGD\n",
    "sgd_model.fit(X_train, y_train)\n",
    "y_pred_sgd_model = sgd_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_sgd_model))\n",
    "print(confusion_matrix(y_test, y_pred_sgd_model))\n",
    "\n",
    "#3-5. Logistic Regression\n",
    "logistic_model.fit(X_train, y_train)\n",
    "y_pred_logistic_model = logistic_model.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred_logistic_model))\n",
    "print(confusion_matrix(y_test, y_pred_logistic_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59c853c",
   "metadata": {},
   "source": [
    "- 결과_1 : 93%의 정확도. \n",
    "- 결과_2 : 98%의 정확도. \n",
    "- 결과_3 : 96%의 정확도. \n",
    "- 결과_4 : 91%의 정확도. \n",
    "- 결과_5 : 95%의 정확도. \n",
    "\n",
    "- 하지만 앞서 공부 한 것과 같이, 종양 검증에 있어 양성,음성 판단유무는 recall 값이 중요함.\n",
    "  - recall 값은 Random Forest 의 수치가 가장 높게 나왔으므로, 제일 적합하다고 보여짐."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
